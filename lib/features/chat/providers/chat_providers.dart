import 'package:flutter_riverpod/flutter_riverpod.dart';
import '../../../core/llm/llm_router.dart';
import '../models/chat_models.dart';

// Chat-specific LLM integration provider
final chatLLMProvider = StateNotifierProvider<ChatLLMNotifier, ChatLLMState>((ref) {
  final llmRouter = ref.watch(llmRouterProvider);
  return ChatLLMNotifier(llmRouter);
});

class ChatLLMState {
  final List<ChatMessage> messages;
  final bool isLoading;
  final String? error;
  final LLMModel? lastUsedModel;

  const ChatLLMState({
    this.messages = const [],
    this.isLoading = false,
    this.error,
    this.lastUsedModel,
  });

  ChatLLMState copyWith({
    List<ChatMessage>? messages,
    bool? isLoading,
    String? error,
    LLMModel? lastUsedModel,
  }) {
    return ChatLLMState(
      messages: messages ?? this.messages,
      isLoading: isLoading ?? this.isLoading,
      error: error,
      lastUsedModel: lastUsedModel ?? this.lastUsedModel,
    );
  }
}

class ChatLLMNotifier extends StateNotifier<ChatLLMState> {
  final LLMRouter _llmRouter;

  ChatLLMNotifier(this._llmRouter) : super(const ChatLLMState()) {
    _addWelcomeMessage();
  }

  void _addWelcomeMessage() {
    final welcomeMessage = ChatMessage(
      text: 'ì•ˆë…•í•˜ì„¸ìš”! ì €ëŠ” SignCare AI ê±´ê°• ìƒë‹´ì‚¬ì…ë‹ˆë‹¤. ğŸ¥\n\nê±´ê°•ê³¼ ê´€ë ¨ëœ ê¶ê¸ˆí•œ ì ì´ ìˆìœ¼ì‹œë©´ ì–¸ì œë“  ë¬¼ì–´ë³´ì„¸ìš”. ì‹ë‹¨, ìš´ë™, ìˆ˜ë©´, ìŠ¤íŠ¸ë ˆìŠ¤ ê´€ë¦¬ ë“± ë‹¤ì–‘í•œ ì£¼ì œë¡œ ë„ì›€ì„ ë“œë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤.',
      isUser: false,
      timestamp: DateTime.now(),
    );

    state = state.copyWith(messages: [welcomeMessage]);
  }

  Future<void> sendMessage(String text) async {
    if (text.trim().isEmpty) return;

    // Add user message immediately
    final userMessage = ChatMessage(
      text: text,
      isUser: true,
      timestamp: DateTime.now(),
    );

    state = state.copyWith(
      messages: [...state.messages, userMessage],
      isLoading: true,
      error: null,
    );

    try {
      // Create LLM request with health context
      final request = LLMRequest(
        message: text,
        context: _buildHealthContext(),
        metadata: {
          'conversation_id': DateTime.now().millisecondsSinceEpoch.toString(),
          'user_type': 'health_consultation',
        },
      );

      // Process request through LLM Router
      final response = await _llmRouter.processRequest(request);

      // Add AI response
      final aiMessage = ChatMessage(
        text: response.response,
        isUser: false,
        timestamp: response.timestamp,
        modelUsed: response.usedModel,
        confidence: response.confidence,
      );

      state = state.copyWith(
        messages: [...state.messages, aiMessage],
        isLoading: false,
        lastUsedModel: response.usedModel,
      );
    } catch (e) {
      // Add error message
      final errorMessage = ChatMessage(
        text: 'ì£„ì†¡í•©ë‹ˆë‹¤. ì¼ì‹œì ì¸ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”.',
        isUser: false,
        timestamp: DateTime.now(),
        isError: true,
      );

      state = state.copyWith(
        messages: [...state.messages, errorMessage],
        isLoading: false,
        error: e.toString(),
      );
    }
  }

  String _buildHealthContext() {
    return '''
ë‹¹ì‹ ì€ SignCare AI ê±´ê°• ìƒë‹´ì‚¬ì…ë‹ˆë‹¤. ë‹¤ìŒ ì§€ì¹¨ì„ ë”°ë¼ ì‘ë‹µí•´ì£¼ì„¸ìš”:

1. ì¹œê·¼í•˜ê³  ì „ë¬¸ì ì¸ í†¤ìœ¼ë¡œ ì‘ë‹µí•˜ì„¸ìš”
2. ê±´ê°• ê´€ë ¨ ì •ë³´ë¥¼ ì •í™•í•˜ê³  ì‹ ë¢°í•  ìˆ˜ ìˆê²Œ ì œê³µí•˜ì„¸ìš”
3. ì‹¬ê°í•œ ì¦ìƒì˜ ê²½ìš° ì „ë¬¸ì˜ ìƒë‹´ì„ ê¶Œí•˜ì„¸ìš”
4. ê°œì¸ì˜ ê±´ê°• ìƒíƒœì— ë§ëŠ” ë§ì¶¤í˜• ì¡°ì–¸ì„ ì œê³µí•˜ì„¸ìš”
5. í•œêµ­ì–´ë¡œ ì‘ë‹µí•˜ë©°, ì˜ë£Œ ìš©ì–´ëŠ” ì‰½ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”

ì£¼ìš” ìƒë‹´ ì˜ì—­:
- ì‹ë‹¨ ê´€ë¦¬ ë° ì˜ì–‘ ìƒë‹´
- ìš´ë™ ë° ì²´ì¤‘ ê´€ë¦¬
- ìˆ˜ë©´ ê°œì„ 
- ìŠ¤íŠ¸ë ˆìŠ¤ ê´€ë¦¬
- ê±´ê°• ìŠµê´€ í˜•ì„±
- ì§ˆë³‘ ì˜ˆë°©

ì‘ë‹µ í˜•ì‹:
- êµ¬ì²´ì ì´ê³  ì‹¤í–‰ ê°€ëŠ¥í•œ ì¡°ì–¸ ì œê³µ
- í•„ìš”ì‹œ ë‹¨ê³„ë³„ ê°€ì´ë“œ ì œì‹œ
- ê´€ë ¨ëœ ì´ëª¨ì§€ ì ì ˆíˆ ì‚¬ìš©
- ì¶”ê°€ ì§ˆë¬¸ì´ë‚˜ ì •ë³´ê°€ í•„ìš”í•œ ê²½ìš° ì•ˆë‚´
''';
  }

  void clearMessages() {
    state = const ChatLLMState();
    _addWelcomeMessage();
  }

  void clearError() {
    state = state.copyWith(error: null);
  }

  void setLLMMode(LLMMode mode) {
    _llmRouter.setMode(mode);
  }

  void setOnlineStatus(bool isOnline) {
    _llmRouter.setOnlineStatus(isOnline);
  }

  void setModelStatus({bool? gemmaLoaded, bool? exaoneLoaded}) {
    _llmRouter.setModelStatus(
      gemmaLoaded: gemmaLoaded,
      exaoneLoaded: exaoneLoaded,
    );
  }

  // Get current LLM status for UI display
  Map<String, dynamic> getLLMStatus() {
    return {
      'mode': _llmRouter.currentMode,
      'isOnline': _llmRouter.isOnline,
      'gemmaAvailable': _llmRouter.isGemmaAvailable,
      'exaoneAvailable': _llmRouter.isExaoneAvailable,
      'lastUsedModel': state.lastUsedModel,
    };
  }
}

// Provider for quick action messages
final quickActionProvider = Provider<Map<String, String>>((ref) {
  return {
    'ì‹ë‹¨ ìƒë‹´': 'í˜„ì¬ ì‹ë‹¨ì— ëŒ€í•œ ì¡°ì–¸ì„ ë°›ê³  ì‹¶ì–´ìš”. ê· í˜•ì¡íŒ ì‹ì‚¬ë¥¼ ìœ„í•œ íŒì„ ì•Œë ¤ì£¼ì„¸ìš”.',
    'ìš´ë™ ì¶”ì²œ': 'ì œ ìƒí™©ì— ë§ëŠ” ìš´ë™ ê³„íšì„ ì„¸ì›Œì£¼ì„¸ìš”. ì–´ë–¤ ìš´ë™ì„ ì–´ë–»ê²Œ ì‹œì‘í•˜ë©´ ì¢‹ì„ê¹Œìš”?',
    'ìˆ˜ë©´ ë¶„ì„': 'ìš”ì¦˜ ì ì„ ì˜ ëª» ìê³  ìˆì–´ìš”. ìˆ˜ë©´ì˜ ì§ˆì„ ê°œì„ í•˜ëŠ” ë°©ë²•ì„ ì•Œë ¤ì£¼ì„¸ìš”.',
    'ìŠ¤íŠ¸ë ˆìŠ¤ ê´€ë¦¬': 'ìŠ¤íŠ¸ë ˆìŠ¤ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ ê´€ë¦¬í•˜ëŠ” ë°©ë²•ê³¼ ë¦´ë ‰ìŠ¤í•˜ëŠ” ë°©ë²•ì„ ì•Œë ¤ì£¼ì„¸ìš”.',
    'ê±´ê°• ì²´í¬': 'ì „ë°˜ì ì¸ ê±´ê°• ìƒíƒœë¥¼ ì²´í¬í•˜ê³  ê°œì„ ì ì„ ì°¾ê³  ì‹¶ì–´ìš”.',
  };
});